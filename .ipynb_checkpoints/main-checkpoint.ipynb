{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instala as bibliotecas necessárias para a execução\n",
    "!pip install pandas\n",
    "!pip install seaborn\n",
    "!pip install numpy\n",
    "!pip install matplotlib\n",
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importando as bibliotecas que serão utilizadas\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, recall_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import warnings\n",
    "\n",
    "#serão ignoradas todas mensagens de warning (aviso) que aparecer no notebook\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abrindo o arquivo com os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arquivo_xls = pd.ExcelFile('data/teste_smarkio_Lbs.xls')\n",
    "dados_analise_ml = pd.read_excel(arquivo_xls, 'Análise_ML')\n",
    "dados_nlp = pd.read_excel(arquivo_xls, 'NLP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#esses dados serão utilizados para resolver as atividades de 1 a 4.\n",
    "dados_analise_ml.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#esses dados serão utilizados para resolver a atividade 5.\n",
    "dados_nlp.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Atividades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1- Análise exploratória dos dados utilizando estatística descritiva e inferencial,considerando uma, duas e/ou mais variáveis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pred_class = classe que foi identificada pelo modelo\n",
    "#probabilidade = a probabilidade da classe que o modelo identificou\n",
    "#status = status da classificação de acordo com um especialista\n",
    "#true_class = classe verdadeira. Se for nula, assumir o valor do pred_class\n",
    "#se pred_class = true_class, então o modelo acertou a classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nós temos um total de 643 dados (também podemos chamar de linhas) e 4 colunas\n",
    "dados_analise_ml.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#primeiramente iremos analisar os tipos das colunas que temos\n",
    "#'pred_class', 'probabilidade' e 'true_class' são colunas numéricas\n",
    "#'status' é do tipo object. Ou seja, se trata de uma coluna categórica\n",
    "dados_analise_ml.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_analise_ml.describe(include='all') #iremos incluir todas as colunas, até mesmo as categóricas (status)\n",
    "\n",
    "#a única coluna que possui valores nulos é a 'true_class', elas serão tratadas posteriormente\n",
    "#a coluna 'status' só possui dois valores possíveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#analisando a coluna 'status'\n",
    "\n",
    "fig = plt.figure(figsize=(6, 4))\n",
    "plt.title('Análise da coluna Status')\n",
    "sns.countplot(dados_analise_ml['status'])\n",
    "fig.savefig('images/analise_status.png')\n",
    "\n",
    "#a coluna 'status' possui dois tipos de valores: approved e revision\n",
    "#approved é o valor que aparece com mais frequência (600), o que representa, aproximadamente, 93% do total\n",
    "#revision aparece somente 43 vezes\n",
    "#isso indica que temos mais dados aprovados do que os que precisam de uma revisão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#analisando a coluna 'true_class'\n",
    "dados_analise_ml_semnull = dados_analise_ml.copy() #armazenando uma cópia do nosso dataframe em outra variável\n",
    "\n",
    "#iremos fazer uma iteração em cada linha do nosso dataframe\n",
    "for index, linha in dados_analise_ml_semnull.iterrows():\n",
    "    \n",
    "    #verificamos se o valor para 'True_class' é nan (nulo)\n",
    "    if np.isnan(linha['True_class']):\n",
    "        \n",
    "        #se for nulo, iremos armazenar o valor do 'Pred_class' no seu lugar\n",
    "        dados_analise_ml_semnull.loc[index, 'True_class'] = linha['Pred_class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verificando se ainda existe algum valor nulo no dataframe e se a inserção funcionou\n",
    "dados_analise_ml_semnull.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verificando se inserimos os valores certos\n",
    "\n",
    "#será criado um dataframe temporário para fazermos a comparação\n",
    "#teremos duas colunas 'True_class': a da esquerda é antes de ser tratada e a direita depois de ser tratada.\n",
    "#veremos que os valores foram inseridos corretamente\n",
    "temp_data = pd.concat([dados_analise_ml, dados_analise_ml_semnull['True_class']], axis=1)\n",
    "temp_data.tail(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#deleta a variável temporária já que não usaremos ela para mais nada\n",
    "del temp_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#usaremos só os dados onde o status é 'approved', pois foram confirmados e aprovados pelos cientistas\n",
    "dados_analise_ml_semnull_approved = dados_analise_ml_semnull[dados_analise_ml_semnull['status'] == 'approved'].copy()\n",
    "\n",
    "fig = plt.figure(figsize=(18, 12))\n",
    "plt.title('Análise da coluna True_class')\n",
    "sns.countplot(y=dados_analise_ml_semnull_approved['True_class'], orient='h')\n",
    "fig.savefig('images/analise_true_class.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#analisando o histograma da coluna 'True_class'\n",
    "fig = plt.figure(figsize=(7, 4))\n",
    "plt.title('Histograma da coluna True_class')\n",
    "sns.histplot(dados_analise_ml_semnull_approved['True_class'])\n",
    "fig.savefig('images/histograma_true_class.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#temos um total de 69 classes diferentes\n",
    "dados_analise_ml_semnull_approved['True_class'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2- Calcule o desempenho do modelo de classificação utilizando pelo menos três métricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Por se tratar de um problema de classificação, as métricas utilizadas são voltadas para\n",
    "#esse tipo de problema.\n",
    "#Um problema de classificação consiste em atribuir uma classe, dentre todas as possibilidades possíveis,\n",
    "#para uma determinada entrada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = confusion_matrix(dados_analise_ml_semnull_approved['True_class'],\n",
    "                                        dados_analise_ml_semnull_approved['Pred_class'])\n",
    "\n",
    "fig = plt.figure(figsize=(24, 18))\n",
    "sns.heatmap(confusion_matrix, cmap='Blues')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = accuracy_score(dados_analise_ml_semnull_approved['True_class'],\n",
    "                       dados_analise_ml_semnull_approved['Pred_class'])\n",
    "\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = f1_score(dados_analise_ml_semnull_approved['True_class'],\n",
    "                 dados_analise_ml_semnull_approved['Pred_class'],\n",
    "                 average='weighted')\n",
    "\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recall Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = recall_score(dados_analise_ml_semnull_approved['True_class'],\n",
    "                     dados_analise_ml_semnull_approved['Pred_class'],\n",
    "                     average='weighted')\n",
    "\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3- Crie um classificador que tenha como output se os dados com status igual a revision estão corretos ou não (Sugestão : Técnica de cross-validation K-fold)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pega somente as linhas onde o status é 'revision'\n",
    "dados_analise_ml_revision = dados_analise_ml_semnull[dados_analise_ml_semnull['status'] == 'revision'].copy()\n",
    "\n",
    "dados_analise_ml_revision.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4- Compare três métricas de avaliação aplicadas ao modelo e descreva sobre a diferença."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5- Crie um classificador, a partir da segunda aba - NLP do arquivo de dados, quepermita identificar qual trecho de música corresponde às respectivas artistas listadas (Sugestão: Naive Bayes Classifier)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#temos 518 dados e duas colunas\n",
    "#colunas: letra e artista\n",
    "#letra: trecho da música\n",
    "#artista: cantora referente ao trecho da música (letra)\n",
    "dados_nlp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verificando se existe linhas com nulo\n",
    "dados_nlp.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(7, 4))\n",
    "plt.title('Análise dos Artistas')\n",
    "sns.countplot(dados_nlp['artista'])\n",
    "\n",
    "#Temos dois artistas: Beyoncé e Rihanna\n",
    "#Beyoncé aparece 274 vezes, aproximadamente 53% \n",
    "#Rihanna aparece 244 vezes, aproximadamente 47%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Criação do classificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separando os dados em X(features) e y(target)\n",
    "\n",
    "X = dados_nlp['letra']\n",
    "y = dados_nlp['artista']\n",
    "\n",
    "#separando os dados para treinamento do classificador e para testá-lo\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=23)\n",
    "\n",
    "#para a extração de features será utilizado o método bags of words\n",
    "#o que esse método faz é associar um número inteiro para cada palavra\n",
    "#e depois armazenará a quantidade de vezes que essa palavra apareceu.\n",
    "#a função CountVectorizer já realiza todo esse processo de pré processamento e \n",
    "#tokenização (associar ao número inteiro) das palavras.\n",
    "cv = CountVectorizer(stop_words='english')\n",
    "\n",
    "X_train_tratado = cv.fit_transform(X_train)\n",
    "X_test_tratado = cv.transform(X_test)\n",
    "\n",
    "naive_bayes = MultinomialNB()\n",
    "\n",
    "#treinando o classificador\n",
    "naive_bayes.fit(X_train_tratado, y_train)\n",
    "\n",
    "#testando o classificador com os dados de teste\n",
    "pred = naive_bayes.predict(X_test_tratado)\n",
    "np.mean(pred == y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
